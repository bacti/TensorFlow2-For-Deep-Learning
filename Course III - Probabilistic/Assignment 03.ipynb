{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RealNVP for the LSUN bedroom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "In this notebook, you will develop the RealNVP normalising flow architecture from scratch, including the affine coupling layers, checkerboard and channel-wise masking, and combining into a multiscale architecture. You will train the normalising flow on a subset of the LSUN bedroom dataset.\n",
    "\n",
    "Some code cells are provided for you in the notebook. You should avoid editing provided code, and make sure to execute the cells in order to avoid unexpected errors. Some cells begin with the line: \n",
    "\n",
    "`#### GRADED CELL ####`\n",
    "\n",
    "Don't move or edit this first line - this is what the automatic grader looks for to recognise graded cells. These cells require you to write your own code to complete them, and are automatically graded when you submit the notebook. Don't edit the function name or signature provided in these cells, otherwise the automatic grader might not function properly.\n",
    "\n",
    "### How to submit\n",
    "\n",
    "Complete all the tasks you are asked for in the worksheet. When you have finished and are happy with your code, press the **Submit Assignment** button at the top of this notebook.\n",
    "\n",
    "### Let's get started!\n",
    "\n",
    "We'll start running some imports, and loading the dataset. Do not edit the existing imports in the following cell. If you would like to make further Tensorflow imports, you should add them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PACKAGE IMPORTS ####\n",
    "\n",
    "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# If you would like to make further imports from tensorflow, add them here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"data/bedroom1.jpg\" alt=\"bedroom 1\" style=\"height: 210px;\"/>  </td>\n",
    "<td> <img src=\"data/bedroom2.jpg\" alt=\"bedroom 2\" style=\"height: 210px;\"/> </td>\n",
    "    <td> <img src=\"data/bedroom3.jpg\" alt=\"bedroom 3\" style=\"height: 210px;\"/> </td>\n",
    "</tr></table>\n",
    "  \n",
    "#### The LSUN Bedroom Dataset\n",
    "\n",
    "In this assignment, you will use a subset of the [LSUN dataset](https://www.yf.io/p/lsun). This is a large-scale image dataset with 10 scene and 20 object categories. A subset of the LSUN bedroom dataset has been provided, and has already been downsampled and preprocessed into smaller, fixed-size images.\n",
    "\n",
    "* F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser and J. Xia. \"LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop\". [arXiv:1506.03365](https://arxiv.org/abs/1506.03365), 10 Jun 2015 \n",
    "\n",
    "Your goal is to develop the RealNVP normalising flow architecture using bijector subclassing, and use it to train a generative model of the LSUN bedroom data subset. For full details on the RealNVP model, refer to the original paper:\n",
    "\n",
    "* L. Dinh, J. Sohl-Dickstein and S. Bengio. \"Density estimation using Real NVP\". [arXiv:1605.08803](https://arxiv.org/abs/1605.08803), 27 Feb 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data\n",
    "\n",
    "The dataset required for this project can be downloaded from the following link:\n",
    "\n",
    "https://drive.google.com/file/d/1scbDZrn5pkRjF_CeZp66uHVQC9o1gIsg/view?usp=sharing\n",
    "\n",
    "You should upload this file to Drive for use in this Colab notebook. It is recommended to unzip it on Drive, which can be done using the `zipfile` package:\n",
    " \n",
    ">```\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"/path/to/lsun_bedroom.zip\",\"r\") as zip_ref:\n",
    "   zip_ref.extractall('lsun_bedroom_data')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset\n",
    "\n",
    "The following functions will be useful for loading and preprocessing the dataset. The subset you will use for this assignment consists of 10,000 training images, 1000 validation images and 1000 test images.\n",
    "\n",
    "The images have been downsampled to 32 x 32 x 3 in order to simplify the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```\n",
    "def load_image(img):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    return img, img\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```\n",
    "def load_dataset(split):\n",
    "    train_list_ds = tf.data.Dataset.from_tensor_slices \\\n",
    "        (np.load('./data/{}.npy'.format(split)))\n",
    "    train_ds = train_list_ds.map(load_image)\n",
    "    return train_ds\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for loading and preprocessing the images\n",
    "def load_image(filepath):\n",
    "    raw_img = tf.io.read_file(filepath) \n",
    "    img_tensor_int = tf.image.decode_jpeg(raw_img, channels = 3)\n",
    "    img_tensor_flt = tf.image.convert_image_dtype(img_tensor_int, tf.float32)\n",
    "    img_tensor_flt = tf.image.resize(img_tensor_flt, [32, 32])\n",
    "    img_tensor_flt = tf.image.random_flip_left_right(img_tensor_flt)\n",
    "    return img_tensor_flt, img_tensor_flt\n",
    "\n",
    "def load_dataset(split):\n",
    "    train_list_ds = tf.data.Dataset.list_files('data/{}/*.jpg'.format(split), shuffle = False)\n",
    "    train_ds = train_list_ds.map(load_image)\n",
    "    return train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training, validation and testing datasets splits\n",
    "train_ds = load_dataset('train')\n",
    "val_ds = load_dataset('val')\n",
    "test_ds = load_dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the datasets\n",
    "\n",
    "shuffle_buffer_size = 1000\n",
    "train_ds = train_ds.shuffle(shuffle_buffer_size)\n",
    "val_ds = val_ds.shuffle(shuffle_buffer_size)\n",
    "test_ds = test_ds.shuffle(shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few examples\n",
    "\n",
    "n_img = 4\n",
    "f, axs = plt.subplots(n_img, n_img, figsize=(14, 14))\n",
    "\n",
    "for k, image in enumerate(train_ds.take(n_img**2)):\n",
    "    i = k // n_img\n",
    "    j = k % n_img\n",
    "    axs[i, j].imshow(image[0])\n",
    "    axs[i, j].axis('off')\n",
    "f.subplots_adjust(wspace=0.01, hspace=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the Dataset objects\n",
    "\n",
    "batch_size = 64\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "test_ds = test_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine coupling layer\n",
    "\n",
    "We will begin the development of the RealNVP architecture with the core bijector that is called the _affine coupling layer_. This bijector can be described as follows: suppose that $x$ is a $D$-dimensional input, and let $d<D$. Then the output $y$ of the affine coupling layer is given by the following equations:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y_{1:d} &= x_{1:d} \\tag{1}\\\\\n",
    "    y_{d+1:D} &= x_{d+1:D}\\odot \\exp(s(x_{1:d})) + t(x_{1:d}), \\tag{2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $s$ and $t$ are functions from $\\mathbb{R}^d\\rightarrow\\mathbb{R}^{D-d}$, and define the log-scale and shift operations on the vector $x_{d+1:D}$ respectively.\n",
    "\n",
    "The log of the Jacobian determinant for this layer is given by $\\sum_{j}s(x_{1:d})_j$.\n",
    "\n",
    "The inverse operation can be easily computed as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_{1:d} &= y_{1:d}\\tag{3}\\\\\n",
    "x_{d+1:D} &= \\left(y_{d+1:D} - t(y_{1:d})\\right)\\odot \\exp(-s(y_{1:d})),\\tag{4}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In practice, we will implement equations $(1)$ and $(2)$ using a binary mask $b$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Forward pass:}\\qquad y &= b\\odot x + (1-b)\\odot\\left(x\\odot\\exp(s(b\\odot x)) + t(b\\odot x)\\right),\\tag{5}\\\\\n",
    "\\text{Inverse pass:}\\qquad x &= b\\odot y + (1-b)\\odot\\left(y - t(b\\odot x)) \\odot\\exp( -s(b\\odot x)\\right).\\tag{6}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs $x$ will be a batch of 3-dimensional Tensors with `height`, `width` and `channels` dimensions. As in the original architecture, we will use both spatial 'checkerboard' masks and channel-wise masks:\n",
    "\n",
    "![Checkerboard and binary masks](data/binary_masks.png)\n",
    "<center>Figure 1. Spatial checkerboard mask (left) and channel-wise mask (right). From the original paper.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom model for log-scale and shift\n",
    "\n",
    "You should now create a custom model for the shift and log-scale parameters that are used in the affine coupling layer bijector. We will use a convolutional residual network, with two residual blocks and a final convolutional layer. Using the functional API, build the model according to the following specifications:\n",
    "\n",
    "* The function takes the `input_shape` and `filters` as arguments\n",
    "* The model should use the `input_shape` in the function argument to set the shape in the Input layer (call this layer `h0`).\n",
    "* The first hidden layer should be a Conv2D layer with number of filters set by the `filters` argument, and a ReLU activation\n",
    "* The second hidden layer should be a BatchNormalization layer\n",
    "* The third hidden layer should be a Conv2D layer with the same number of filters as the input `h0` to the model, and a ReLU activation\n",
    "* The fourth hidden layer should be a BatchNormalization layer\n",
    "* The fifth hidden layer should be the sum of the fourth hidden layer output and the inputs `h0`. Call this layer `h1`\n",
    "* The sixth hidden layer should be a Conv2D layer with filters set by the `filters` argument, and a ReLU activation\n",
    "* The seventh hidden layer should be a BatchNormalization layer\n",
    "* The eighth hidden layer should be a Conv2D layer with the same number of filters as `h1` (and `h0`), and a ReLU activation\n",
    "* The ninth hidden layer should be a BatchNormalization layer\n",
    "* The tenth hidden layer should be the sum of the ninth hidden layer output and `h1`\n",
    "* The eleventh hidden layer should be a Conv2D layer with the number of filters equal to twice the number of channels of the model input, and a linear activation. Call this layer `h2`\n",
    "* The twelfth hidden layer should split `h2` into two equal-sized Tensors along the final channel axis. These two Tensors are the shift and log-scale Tensors, and should each have the same shape as the model input\n",
    "* The final layer should then apply the `tanh` nonlinearity to the log_scale Tensor. The outputs to the model should then be the list of Tensors `[shift, log_scale]`\n",
    "\n",
    "All Conv2D layers should use a 3x3 kernel size, `\"SAME\"` padding and an $l2$ kernel regularizer with regularisation coefficient of `5e-5`.\n",
    "\n",
    "_Hint: use_ `tf.split` _with arguments_ `num_or_size_splits=2, axis=-1` _to create the output Tensors_.\n",
    "\n",
    "In total, the network should have 14 layers (including the `Input` layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_conv_resnet(input_shape, filters):\n",
    "    \"\"\"\n",
    "    This function should build a CNN ResNet model according to the above specification,\n",
    "    using the functional API. The function takes input_shape as an argument, which should be\n",
    "    used to specify the shape in the Input layer, as well as a filters argument, which\n",
    "    should be used to specify the number of filters in (some of) the convolutional layers.\n",
    "    Your function should return the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function and print the model summary\n",
    "\n",
    "conv_resnet = get_conv_resnet((32, 32, 3), 32)\n",
    "conv_resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also inspect your model architecture graphically by running the following cell. It should look something like the following:\n",
    "\n",
    "![ResNet plot](data/model_plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model graph\n",
    "\n",
    "tf.keras.utils.plot_model(conv_resnet, show_layer_names=False, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output shapes are as expected\n",
    "\n",
    "print(conv_resnet(tf.random.normal((1, 32, 32, 3)))[0].shape)\n",
    "print(conv_resnet(tf.random.normal((1, 32, 32, 3)))[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary masks\n",
    "\n",
    "Now that you have a shift and log-scale model built, we will now implement the affine coupling layer. We will first need functions to create the binary masks $b$ as described above. The following function creates the spatial 'checkerboard' mask.\n",
    "\n",
    "It takes a rank-2 `shape` as input, which correspond to the `height` and `width` dimensions, as well as an `orientation` argument (an integer equal to `0` or `1`) that determines which way round the zeros and ones are entered into the Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the checkerboard mask\n",
    "\n",
    "def checkerboard_binary_mask(shape, orientation=0):\n",
    "    height, width = shape[0], shape[1]\n",
    "    height_range = tf.range(height)\n",
    "    width_range = tf.range(width)\n",
    "    height_odd_inx = tf.cast(tf.math.mod(height_range, 2), dtype=tf.bool)\n",
    "    width_odd_inx = tf.cast(tf.math.mod(width_range, 2), dtype=tf.bool)\n",
    "    odd_rows = tf.tile(tf.expand_dims(height_odd_inx, -1), [1, width])\n",
    "    odd_cols = tf.tile(tf.expand_dims(width_odd_inx, 0), [height, 1])\n",
    "    checkerboard_mask = tf.math.logical_xor(odd_rows, odd_cols)\n",
    "    if orientation == 1:\n",
    "        checkerboard_mask = tf.math.logical_not(checkerboard_mask)\n",
    "    return tf.cast(tf.expand_dims(checkerboard_mask, -1), tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function creates a rank-3 Tensor to mask the `height`, `width` and `channels` dimensions of the input. We can take a look at this checkerboard mask for some example inputs below. In order to make the Tensors easier to inspect, we will squeeze out the single channel dimension (which is always 1 for this mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the checkerboard_binary_mask function to see an example\n",
    "# NB: we squeeze the shape for easier viewing. The full shape is (4, 4, 1)\n",
    "\n",
    "tf.squeeze(checkerboard_binary_mask((4, 4), orientation=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The `orientation` should be 0 or 1, and determines which way round the binary entries are\n",
    "\n",
    "tf.squeeze(checkerboard_binary_mask((4, 4), orientation=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now complete the following function to create a channel-wise mask. This function takes a single integer `num_channels` as an input, as well as an `orientation` argument, similar to above. You can assume that the `num_channels` integer is even. \n",
    "\n",
    "The function should return a rank-3 Tensor with singleton entries for `height` and `width`. In the channel axis, the first `num_channels // 2` entries should be zero (for `orientation=0`) and the final `num_channels // 2` entries should be one (for `orientation=0`). The zeros and ones should be reversed for `orientation=1`. The `dtype` of the returned Tensor should be `tf.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def channel_binary_mask(num_channels, orientation=0):\n",
    "    \"\"\"\n",
    "    This function takes an integer num_channels and orientation (0 or 1) as\n",
    "    arguments. It should create a channel-wise binary mask with \n",
    "    dtype=tf.float32, according to the above specification.\n",
    "    The function should then return the binary mask.\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to see an example channel-wise binary mask\n",
    "\n",
    "channel_binary_mask(6, orientation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following functions. \n",
    "# Make sure to not change the function names or arguments.\n",
    "\n",
    "def forward(x, b, shift_and_log_scale_fn):\n",
    "    \"\"\"\n",
    "    This function takes the input Tensor x, binary mask b and callable\n",
    "    shift_and_log_scale_fn as arguments.\n",
    "    This function should implement the forward transformation in equation (5)\n",
    "    and return the output Tensor y, which will have the same shape as x\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def inverse(y, b, shift_and_log_scale_fn):\n",
    "    \"\"\"\n",
    "    This function takes the input Tensor x, binary mask b and callable\n",
    "    shift_and_log_scale_fn as arguments.\n",
    "    This function should implement the forward transformation in equation (5)\n",
    "    and return the output Tensor y, which will have the same shape as x\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new bijector class also requires the `log_det_jacobian` methods to be implemented. Recall that the log of the Jacobian determinant of the forward transformation is given by $\\sum_{j}s(x_{1:d})_j$, where $s$ is the log-scale function of the affine coupling layer. \n",
    "\n",
    "You should now complete the following functions to define the `forward_log_det_jacobian` and `inverse_log_det_jacobian` methods of the affine coupling layer bijector.\n",
    "\n",
    "* Both functions `forward_log_det_jacobian` and `inverse_log_det_jacobian` takes an input Tensor `x` (or `y`), a rank-3 binary mask `b`, and the `shift_and_log_scale_fn` callable \n",
    "* These arguments are the same as the description for the `forward` and `inverse` functions\n",
    "* The `forward_log_det_jacobian` function should implement the log of the Jacobian determinant for the transformation $(5)$\n",
    "* The `inverse_log_det_jacobian` function should implement the log of the Jacobian determinant for the transformation $(6)$\n",
    "* Both functions should reduce sum over the last three axes of the input Tensor (`height`, `width` and `channels`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following functions. \n",
    "# Make sure to not change the function names or arguments.\n",
    "\n",
    "def forward_log_det_jacobian(x, b, shift_and_log_scale_fn):\n",
    "    \"\"\"\n",
    "    This function takes the input Tensor x, binary mask b and callable\n",
    "    shift_and_log_scale_fn as arguments.\n",
    "    This function should compute and return the log of the Jacobian determinant \n",
    "    of the forward transformation in equation (5)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def inverse_log_det_jacobian(y, b, shift_and_log_scale_fn):\n",
    "    \"\"\"\n",
    "    This function takes the input Tensor y, binary mask b and callable\n",
    "    shift_and_log_scale_fn as arguments.\n",
    "    This function should compute and return the log of the Jacobian determinant \n",
    "    of the forward transformation in equation (6)\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to create the coupling layer bijector, using bijector subclassing. You should complete the class below to define the `AffineCouplingLayer`. \n",
    "\n",
    "* You should complete the initialiser `__init__`, and the internal class method `_get_mask`\n",
    "* The `_forward`, `_inverse`, `_forward_log_det_jacobian` and `_inverse_log_det_jacobian` methods are completed for you using the functions you have written above. Do not modify these methods\n",
    "* The initialiser takes the `shift_and_log_scale_fn` callable, `mask_type` string (either `\"checkerboard\"` or `\"channel\"`, `orientation` (integer, either `0` or `1`) as required arguments, and allows for extra keyword arguments\n",
    "  * The required arguments should be set as class attributes in the initialiser (note that the `shift_and_log_scale_fn` attribute is being used in the `_forward`, `_inverse`, `_forward_log_det_jacobian` and `_inverse_log_det_jacobian` methods)\n",
    "  * The initialiser should call the base class initialiser, and pass in any extra keyword arguments\n",
    "  * The class should have a required number of event dimensions equal to 3\n",
    "* The internal method `_get_mask` takes a `shape` as an argument, which is the shape of an input Tensor\n",
    "  * This method should use the `checkerboard_binary_mask` and `channel_binary_mask` functions above, as well as the `mask_type` and `orientation` arguments passed to the initialiser to compute and return the required binary mask\n",
    "  * This method is used in each of the `_forward`, `_inverse`, `_forward_log_det_jacobian` and `_inverse_log_det_jacobian` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following class. \n",
    "# Make sure to not change the class or method names or arguments.\n",
    "\n",
    "class AffineCouplingLayer(tfb.Bijector):\n",
    "    \"\"\"\n",
    "    Class to implement the affine coupling layer.\n",
    "    Complete the __init__ and _get_mask methods according to the instructions above.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shift_and_log_scale_fn, mask_type, orientation, **kwargs):\n",
    "        \"\"\"\n",
    "        The class initialiser takes the shift_and_log_scale_fn callable, mask_type,\n",
    "        orientation and possibly extra keywords arguments. It should call the \n",
    "        base class initialiser, passing any extra keyword arguments along. \n",
    "        It should also set the required arguments as class attributes.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _get_mask(self, shape):\n",
    "        \"\"\"\n",
    "        This internal method should use the binary mask functions above to compute\n",
    "        and return the binary mask, according to the arguments passed in to the\n",
    "        initialiser.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "\n",
    "    def _forward(self, x):\n",
    "        b = self._get_mask(x.shape)\n",
    "        return forward(x, b, self.shift_and_log_scale_fn)\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        b = self._get_mask(y.shape)\n",
    "        return inverse(y, b, self.shift_and_log_scale_fn)\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        b = self._get_mask(x.shape)\n",
    "        return forward_log_det_jacobian(x, b, self.shift_and_log_scale_fn)\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        b = self._get_mask(y.shape)\n",
    "        return inverse_log_det_jacobian(y, b, self.shift_and_log_scale_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function by creating an instance of the AffineCouplingLayer class\n",
    "\n",
    "affine_coupling_layer = AffineCouplingLayer(conv_resnet, 'channel', orientation=1, \n",
    "                                            name='affine_coupling_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following should return a Tensor of the same shape as the input\n",
    "\n",
    "affine_coupling_layer.forward(tf.random.normal((16, 32, 32, 3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following should compute a log_det_jacobian for each event in the batch\n",
    "\n",
    "affine_coupling_layer.forward_log_det_jacobian(tf.random.normal((16, 32, 32, 3)), event_ndims=3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the affine coupling layers\n",
    "\n",
    "In the affine coupling layer, part of the input remains unchanged in the transformation $(5)$. In order to allow transformation of all of the input, several coupling layers are composed, with the orientation of the mask being reversed in subsequent layers.\n",
    "\n",
    "<img src=\"data/alternating_masks.png\" alt=\"Coupling layers\" style=\"height: 240px;\"/>\n",
    "<center>Figure 2. RealNVP alternates the orientation of masks from one affine coupling layer to the next. From the original paper.</center>\n",
    "\n",
    "Our model design will be similar to the original architecture; we will compose three affine coupling layers with checkerboard masking, followed by a batch normalization bijector (`tfb.BatchNormalization` is a built-in bijector), followed by a squeezing operation, followed by three more affine coupling layers with channel-wise masking and a final batch normalization bijector. \n",
    "\n",
    "The squeezing operation divides the spatial dimensions into 2x2 squares, and reshapes a Tensor of shape `(H, W, C)` into a Tensor of shape `(H // 2, W // 2, 4 * C)` as shown in Figure 1.\n",
    "\n",
    "The squeezing operation is also a bijective operation, and has been provided for you in the class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bijector class for the squeezing operation\n",
    "\n",
    "class Squeeze(tfb.Bijector):\n",
    "    \n",
    "    def __init__(self, name='Squeeze', **kwargs):\n",
    "        super(Squeeze, self).__init__(forward_min_event_ndims=3, is_constant_jacobian=True, \n",
    "                                      name=name, **kwargs)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        input_shape = x.shape\n",
    "        height, width, channels = input_shape[-3:]\n",
    "        y = tfb.Reshape((height // 2, 2, width // 2, 2, channels), event_shape_in=(height, width, channels))(x)\n",
    "        y = tfb.Transpose(perm=[0, 2, 1, 3, 4])(y)\n",
    "        y = tfb.Reshape((height // 2, width // 2, 4 * channels),\n",
    "                        event_shape_in=(height // 2, width // 2, 2, 2, channels))(y)\n",
    "        return y\n",
    "\n",
    "    def _inverse(self, y):\n",
    "        input_shape = y.shape\n",
    "        height, width, channels = input_shape[-3:]\n",
    "        x = tfb.Reshape((height, width, 2, 2, channels // 4), event_shape_in=(height, width, channels))(y)\n",
    "        x = tfb.Transpose(perm=[0, 2, 1, 3, 4])(x)\n",
    "        x = tfb.Reshape((2 * height, 2 * width, channels // 4),\n",
    "                        event_shape_in=(height, 2, width, 2, channels // 4))(x)\n",
    "        return x\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        return tf.constant(0., x.dtype)\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        return tf.constant(0., y.dtype)\n",
    "\n",
    "    def _forward_event_shape_tensor(self, input_shape):\n",
    "        height, width, channels = input_shape[-3], input_shape[-2], input_shape[-1]\n",
    "        return height // 2, width // 2, 4 * channels\n",
    "\n",
    "    def _inverse_event_shape_tensor(self, output_shape):\n",
    "        height, width, channels = output_shape[-3], output_shape[-2], output_shape[-1]\n",
    "        return height * 2, width * 2, channels // 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the effect of the squeezing operation on some example inputs in the cells below. In the forward transformation, each spatial dimension is halved, whilst the channel dimension is multiplied by 4. The opposite happens in the inverse transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Squeeze bijector\n",
    "\n",
    "squeeze = Squeeze()\n",
    "squeeze(tf.ones((10, 32, 32, 3))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the inverse operation\n",
    "\n",
    "squeeze.inverse(tf.ones((10, 4, 4, 96))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now construct a block of coupling layers according to the architecture described above. You should complete the following function to chain together the bijectors that we have constructed, to form a bijector that performs the following operations in the forward transformation:\n",
    "\n",
    "* Three `AffineCouplingLayer` bijectors with `\"checkerboard\"` masking with orientations `0, 1, 0` respectively\n",
    "* A `BatchNormalization` bijector\n",
    "* A `Squeeze` bijector\n",
    "* Three more `AffineCouplingLayer` bijectors with `\"channel\"` masking with orientations `0, 1, 0` respectively\n",
    "* Another `BatchNormalization` bijector\n",
    "\n",
    "The function takes the following arguments:\n",
    "* `shift_and_log_scale_fns`: a list or tuple of six conv_resnet models\n",
    "  * The first three models in this list are used in the three coupling layers with checkerboard masking\n",
    "  * The last three models in this list are used in the three coupling layers with channel masking\n",
    "* `squeeze`: an instance of the `Squeeze` bijector\n",
    "\n",
    "_NB: at this point, we would like to point out that we are following the exposition in the original paper, and think of the forward transformation as acting on the input image. Note that this is in contrast to the convention of using the forward transformation for sampling, and the inverse transformation for computing log probs._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def realnvp_block(shift_and_log_scale_fns, squeeze):\n",
    "    \"\"\"\n",
    "    This function takes a list or tuple of six conv_resnet models, and an \n",
    "    instance of the Squeeze bijector.\n",
    "    The function should construct the chain of bijectors described above,\n",
    "    using the conv_resnet models in the coupling layers.\n",
    "    The function should then return the chained bijector.\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your function to create an instance of the bijector\n",
    "\n",
    "checkerboard_fns = []\n",
    "for _ in range(3):\n",
    "    checkerboard_fns.append(get_conv_resnet((32, 32, 3), 512))\n",
    "channel_fns = []\n",
    "for _ in range(3):\n",
    "    channel_fns.append(get_conv_resnet((16, 16, 12), 512))\n",
    "    \n",
    "block = realnvp_block(checkerboard_fns + channel_fns, squeeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the bijector on a dummy input\n",
    "\n",
    "block.forward(tf.random.normal((10, 32, 32, 3))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiscale architecture\n",
    "\n",
    "The final component of the RealNVP is the multiscale architecture. The squeeze operation reduces the spatial dimensions but increases the channel dimensions. After one of the blocks of coupling-squeeze-coupling that you have implemented above, half of the dimensions are factored out as latent variables, while the other half is further processed through subsequent layers. This results in latent variables that represent different scales of features in the model.\n",
    "\n",
    "<img src=\"data/multiscale.png\" alt=\"Multiscale architecture\" style=\"height: 320px;\"/>\n",
    "<center>Figure 3. RealNVP creates latent variables at different scales by factoring out half of the dimensions at each scale. From the original paper.</center>\n",
    "\n",
    "The final scale does not use the squeezing operation, and instead applies four affine coupling layers with alternating checkerboard masks.\n",
    "\n",
    "The multiscale architecture for two latent variable scales is implemented for you in the following bijector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bijector to implement the multiscale architecture\n",
    "\n",
    "class RealNVPMultiScale(tfb.Bijector):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(RealNVPMultiScale, self).__init__(forward_min_event_ndims=3, **kwargs)\n",
    "\n",
    "        # First level\n",
    "        shape1 = (32, 32, 3)  # Input shape\n",
    "        shape2 = (16, 16, 12)  # Shape after the squeeze operation\n",
    "        shape3 = (16, 16, 6)  # Shape after factoring out the latent variable\n",
    "        self.conv_resnet1 = get_conv_resnet(shape1, 64)\n",
    "        self.conv_resnet2 = get_conv_resnet(shape1, 64)\n",
    "        self.conv_resnet3 = get_conv_resnet(shape1, 64)\n",
    "        self.conv_resnet4 = get_conv_resnet(shape2, 128)\n",
    "        self.conv_resnet5 = get_conv_resnet(shape2, 128)\n",
    "        self.conv_resnet6 = get_conv_resnet(shape2, 128)\n",
    "        self.squeeze = Squeeze()\n",
    "        self.block1 = realnvp_block([self.conv_resnet1, self.conv_resnet2,\n",
    "                                    self.conv_resnet3, self.conv_resnet4,\n",
    "                                    self.conv_resnet5, self.conv_resnet6], self.squeeze)\n",
    "\n",
    "        # Second level\n",
    "        self.conv_resnet7 = get_conv_resnet(shape3, 128)\n",
    "        self.conv_resnet8 = get_conv_resnet(shape3, 128)\n",
    "        self.conv_resnet9 = get_conv_resnet(shape3, 128)\n",
    "        self.conv_resnet10 = get_conv_resnet(shape3, 128)\n",
    "        self.coupling_layer1 = AffineCouplingLayer(self.conv_resnet7, 'checkerboard', 0)\n",
    "        self.coupling_layer2 = AffineCouplingLayer(self.conv_resnet8, 'checkerboard', 1)\n",
    "        self.coupling_layer3 = AffineCouplingLayer(self.conv_resnet9, 'checkerboard', 0)\n",
    "        self.coupling_layer4 = AffineCouplingLayer(self.conv_resnet10, 'checkerboard', 1)\n",
    "        self.block2 = tfb.Chain([self.coupling_layer4, self.coupling_layer3,\n",
    "                                 self.coupling_layer2, self.coupling_layer1])\n",
    "\n",
    "    def _forward(self, x):\n",
    "        h1 = self.block1.forward(x)\n",
    "        z1, h2 = tf.split(h1, 2, axis=-1)\n",
    "        z2 = self.block2.forward(h2)\n",
    "        return tf.concat([z1, z2], axis=-1)\n",
    "        \n",
    "    def _inverse(self, y):\n",
    "        z1, z2 = tf.split(y, 2, axis=-1)\n",
    "        h2 = self.block2.inverse(z2)\n",
    "        h1 = tf.concat([z1, h2], axis=-1)\n",
    "        return self.block1.inverse(h1)\n",
    "\n",
    "    def _forward_log_det_jacobian(self, x):\n",
    "        log_det1 = self.block1.forward_log_det_jacobian(x, event_ndims=3)\n",
    "        h1 = self.block1.forward(x)\n",
    "        _, h2 = tf.split(h1, 2, axis=-1)\n",
    "        log_det2 = self.block2.forward_log_det_jacobian(h2, event_ndims=3)\n",
    "        return log_det1 + log_det2\n",
    "\n",
    "    def _inverse_log_det_jacobian(self, y):\n",
    "        z1, z2 = tf.split(y, 2, axis=-1)\n",
    "        h2 = self.block2.inverse(z2)\n",
    "        log_det2 = self.block2.inverse_log_det_jacobian(z2, event_ndims=3)\n",
    "        h1 = tf.concat([z1, h2], axis=-1)\n",
    "        log_det1 = self.block1.inverse_log_det_jacobian(h1, event_ndims=3)\n",
    "        return log_det1 + log_det2\n",
    "\n",
    "    def _forward_event_shape_tensor(self, input_shape):\n",
    "        height, width, channels = input_shape[-3], input_shape[-2], input_shape[-1]\n",
    "        return height // 4, width // 4, 16 * channels\n",
    "\n",
    "    def _inverse_event_shape_tensor(self, output_shape):\n",
    "        height, width, channels = output_shape[-3], output_shape[-2], output_shape[-1]\n",
    "        return 4 * height, 4 * width, channels // 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the multiscale architecture\n",
    "\n",
    "multiscale_bijector = RealNVPMultiScale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing bijector\n",
    "\n",
    "We will also preprocess the image data before sending it through the RealNVP model. To do this, for a Tensor $x$ of pixel values in $[0, 1]^D$, we transform $x$ according to the following:\n",
    "\n",
    "$$\n",
    "T(x) = \\text{logit}\\left(\\alpha + (1 - 2\\alpha)x\\right),\\tag{7}\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is a parameter, and the logit function is the inverse of the sigmoid function, and is given by \n",
    "\n",
    "$$\n",
    "\\text{logit}(p) = \\log (p) - \\log (1 - p).\n",
    "$$\n",
    "\n",
    "You should now complete the following function to construct this bijector from in-built bijectors from the bijectors module.\n",
    "\n",
    "* The function takes the parameter `alpha` as an input, which you can assume to take a small positive value ($\\ll0.5$)\n",
    "* The function should construct and return a bijector that computes $(7)$ in the forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GRADED CELL ####\n",
    "\n",
    "# Complete the following function. \n",
    "# Make sure to not change the function name or arguments.\n",
    "\n",
    "def get_preprocess_bijector(alpha):\n",
    "    \"\"\"\n",
    "    This function should create a chained bijector that computes the \n",
    "    transformation T in equation (7) above.\n",
    "    This can be computed using in-built bijectors from the bijectors module.\n",
    "    Your function should then return the chained bijector.\n",
    "    \"\"\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the preprocess bijector\n",
    "\n",
    "preprocess = get_preprocess_bijector(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the RealNVP model\n",
    "\n",
    "Finally, we will use our RealNVP model to train\n",
    "\n",
    "We will use the following model class to help with the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class for training\n",
    "\n",
    "class RealNVPModel(Model):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RealNVPModel, self).__init__(**kwargs)\n",
    "        self.preprocess = get_preprocess_bijector(0.05)\n",
    "        self.realnvp_multiscale = RealNVPMultiScale()\n",
    "        self.bijector = tfb.Chain([self.realnvp_multiscale, self.preprocess])\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        output_shape = self.bijector(tf.expand_dims(tf.zeros(input_shape[1:]), axis=0)).shape\n",
    "        self.base = tfd.Independent(tfd.Normal(loc=tf.zeros(output_shape[1:]), scale=1.),\n",
    "                                    reinterpreted_batch_ndims=3)\n",
    "        self._bijector_variables = (\n",
    "            list(self.bijector.variables))\n",
    "        self.flow = tfd.TransformedDistribution(\n",
    "            distribution=self.base,\n",
    "            bijector=tfb.Invert(self.bijector),\n",
    "        )\n",
    "        super(RealNVPModel, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        return self.flow\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        sample = self.base.sample(batch_size)\n",
    "        return self.bijector.inverse(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the RealNVPModel class\n",
    "\n",
    "realnvp_model = RealNVPModel()\n",
    "realnvp_model.build((1, 32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of variables in the model\n",
    "\n",
    "print(\"Total trainable variables:\")\n",
    "print(sum([np.prod(v.shape) for v in realnvp_model.trainable_variables]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the model's `call` method returns the `TransformedDistribution` object. Also, we have set up our datasets to return the input image twice as a 2-tuple. This is so we can train our model with negative log-likelihood as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the negative log-likelihood loss function\n",
    "\n",
    "def nll(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to use the GPU accelerator hardware on Colab to train this model, as it can take some time to train. Note that it is not required to train the model in order to pass this assignment. For optimal results, a larger model should be trained for longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "\n",
    "realnvp_model.compile(loss=nll, optimizer=Adam())\n",
    "realnvp_model.fit(train_ds, validation_data=val_ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "realnvp_model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the model\n",
    "\n",
    "samples = realnvp_model.sample(8).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the samples\n",
    "\n",
    "n_img = 8\n",
    "f, axs = plt.subplots(2, n_img // 2, figsize=(14, 7))\n",
    "\n",
    "for k, image in enumerate(samples):\n",
    "    i = k % 2\n",
    "    j = k // 2\n",
    "    axs[i, j].imshow(np.clip(image, 0., 1.))\n",
    "    axs[i, j].axis('off')\n",
    "f.subplots_adjust(wspace=0.01, hspace=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on completing this programming assignment! In the next week of the course we will look at the variational autoencoder."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "coursera": {
   "course_slug": "probabilistic-deep-learning-with-tensorflow2",
   "graded_item_id": "qXCvM",
   "launcher_item_id": "wGJ88"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
